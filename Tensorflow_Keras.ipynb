{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([keras.layers.Dense(units = 1, input_shape = [1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'sgd', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype = float)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(xs, ys, epochs = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.predict([10])[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "In this exercise you'll try to build a neural network that predicts the price of a house according to a simple formula.\n",
    "So, imagine if house pricing was as easy as a house costs 50k + 50k per bedroom, so that a 1 bedroom house costs 100k, a 2 bedroom house costs 150k etc.\n",
    "How would you create a neural network that learns this relationship so that it would predict a 7 bedroom house as costing close to 400k etc.\n",
    "Hint: Your network might work better if you scale the house price down. You don't have to give the answer 400...it might be better to create something that predicts the number 4, and then your answer is in the 'hundreds of thousands' etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([keras.layers.Dense(units = 1, input_shape = [1])])\n",
    "model.compile(optimizer = 'sgd', loss = 'mean_squared_error')\n",
    "xs = np.array([0, 1,2,3,4,5], dtype = float)\n",
    "ys = np.array([0.5, 1, 1.5, 2, 2.5, 3], dtype = float)\n",
    "model.fit(xs, ys, epochs = 500)\n",
    "print(model.predict([7.0])[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(training_images[0])\n",
    "print(training_labels[0])\n",
    "print(training_images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_images  = training_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
    "                                   tf.keras.layers.Dense(512, activation = tf.nn.relu),\n",
    "                                   tf.keras.layers.Dense(10, activation = tf.nn.softmax)])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(training_images, training_labels, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifications = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifications[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(test_images[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs = {}):\n",
    "        if(logs.get('acc') > 0.8):\n",
    "            print('\\nReached 80% accuracy so cancelling training')\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "callbacks = myCallback()\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)\n",
    "\n",
    "classifications = model.predict(x_test)\n",
    "\n",
    "print(classifications[0])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "In the course you learned how to do classification using Fashion MNIST, a data set containing items of clothing. There's another, similar dataset called MNIST which has items of handwriting -- the digits 0 through 9.\n",
    "\n",
    "Write an MNIST classifier that trains to 99% accuracy or above, and does it without a fixed number of epochs -- i.e. you should stop training once you reach that level of accuracy.\n",
    "\n",
    "Some notes:\n",
    "1. It should succeed in less than 10 epochs, so it is okay to change epochs to 10, but nothing larger\n",
    "2. When it reaches 99% or greater it should print out the string \"Reached 99% accuracy so cancelling training!\"\n",
    "3. If you add any additional variables, make sure you use the same names as the ones used in the class\n",
    "\n",
    "I've started the code for you below -- how would you finish it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# YOUR CODE SHOULD START HERE\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs = {}):\n",
    "        if(logs.get('acc') > 0.99):\n",
    "            print('\\nReached 99% accuracy so cancelling training')\n",
    "            self.model.stop_training = True\n",
    "# YOUR CODE SHOULD END HERE\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "print(x_train[0])\n",
    "# YOUR CODE SHOULD START HERE\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "callbacks = myCallback()\n",
    "# YOUR CODE SHOULD END HERE\n",
    "model = tf.keras.models.Sequential([\n",
    "# YOUR CODE SHOULD START HERE\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation = tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n",
    "# YOUR CODE SHOULD END HERE\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# YOUR CODE SHOULD START HERE\n",
    "model.fit(x_train, y_train, epochs = 10, callbacks = [callbacks])\n",
    "# YOUR CODE SHOULD END HERE\n",
    "\n",
    "model.evaluate(x_test, y_test)\n",
    "classifications = model.predict(x_test)\n",
    "\n",
    "print(classifications[0])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Improving Computer Vision Accuracy using Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "training_images = training_images.reshape(60000, 28, 28, 1)\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28,28,1)\n",
    "test_images = test_images / 255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', input_shape = (28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "])\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()\n",
    "model.fit(training_images, training_labels, epochs = 5)\n",
    "test_loss = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now instead of the input layer at the top, you're going to add a Convolution. The parameters are:\n",
    "\n",
    "1. The number of convolutions you want to generate. Purely arbitrary, but good to start with something in the order of 32\n",
    "2. The size of the Convolution, in this case a 3x3 grid\n",
    "3. The activation function to use -- in this case we'll use relu, which you might recall is the equivalent of returning x when x>0, else returning 0\n",
    "4. In the first layer, the shape of the input data.\n",
    "\n",
    "You'll follow the Convolution with a MaxPooling layer which is then designed to compress the image, while maintaining the content of the features that were highlighted by the convlution. By specifying (2,2) for the MaxPooling, the effect is to quarter the size of the image. Without going into too much detail here, the idea is that it creates a 2x2 array of pixels, and picks the biggest one, thus turning 4 pixels into 1. It repeats this across the image, and in so doing halves the number of horizontal, and halves the number of vertical pixels, effectively reducing the image by 25%.\n",
    "\n",
    "You can call model.summary() to see the size and shape of the network, and you'll notice that after every MaxPooling layer, the image size is reduced in this way. \n",
    "\n",
    "\n",
    "```\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add another convolution\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "f, axarr = plt.subplots(3,4)\n",
    "FIRST_IMAGE=0\n",
    "SECOND_IMAGE=7\n",
    "THIRD_IMAGE=26\n",
    "CONVOLUTION_NUMBER = 1\n",
    "from tensorflow.keras import models\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = tf.keras.models.Model(inputs = model.input, outputs = layer_outputs)\n",
    "for x in range(0,4):\n",
    "    f1 = activation_model.predict(test_images[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "    axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "    axarr[0,x].grid(False)\n",
    "    f2 = activation_model.predict(test_images[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "    axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "    axarr[1,x].grid(False)\n",
    "    f3 = activation_model.predict(test_images[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\n",
    "    axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\n",
    "    axarr[2,x].grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore how convolutions work by creating a basic convolution on a 2D Grey Scale image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "i = misc.ascent()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.grid(False)\n",
    "plt.gray()\n",
    "plt.axis('off')\n",
    "plt.imshow(i)\n",
    "plt.show()\n",
    "\n",
    "i_transformed = np.copy(i)\n",
    "size_x = i_transformed.shape[0]\n",
    "size_y = i_transformed.shape[1]\n",
    "\n",
    "filter = [ [1, 0, -1], [1, 0, -1], [1, 0, -1]]\n",
    "# filter = [ [0, 1, 0], [1, -4, 1], [0, 1, 0]]\n",
    "# A couple more filters to try for fun!\n",
    "# filter = [ [-1, -2, -1], [0, 0, 0], [1, 2, 1]]\n",
    "# filter = [ [-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]\n",
    "\n",
    "weight = 1\n",
    "\n",
    "for x in range(1,size_x-1):\n",
    "    for y in range(1,size_y-1):\n",
    "        convolution = 0.0\n",
    "        convolution = convolution + (i[x - 1, y-1] * filter[0][0])\n",
    "        convolution = convolution + (i[x, y-1] * filter[0][1])\n",
    "        convolution = convolution + (i[x + 1, y-1] * filter[0][2])\n",
    "        convolution = convolution + (i[x-1, y] * filter[1][0])\n",
    "        convolution = convolution + (i[x, y] * filter[1][1])\n",
    "        convolution = convolution + (i[x+1, y] * filter[1][2])\n",
    "        convolution = convolution + (i[x-1, y+1] * filter[2][0])\n",
    "        convolution = convolution + (i[x, y+1] * filter[2][1])\n",
    "        convolution = convolution + (i[x+1, y+1] * filter[2][2])\n",
    "        convolution = convolution * weight\n",
    "        if(convolution<0):\n",
    "            convolution=0\n",
    "        if(convolution>255):\n",
    "            convolution=255\n",
    "        i_transformed[x, y] = convolution\n",
    "\n",
    "# Plot the image. Note the size of the axes -- they are 512 by 512\n",
    "plt.gray()\n",
    "plt.grid(False)\n",
    "plt.imshow(i_transformed)\n",
    "#plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "new_x = int(size_x/2)\n",
    "new_y = int(size_y/2)\n",
    "newImage = np.zeros((new_x, new_y))\n",
    "for x in range(0, size_x, 2):\n",
    "    for y in range(0, size_y, 2):\n",
    "        pixels = []\n",
    "        pixels.append(i_transformed[x, y])\n",
    "        pixels.append(i_transformed[x+1, y])\n",
    "        pixels.append(i_transformed[x, y+1])\n",
    "        pixels.append(i_transformed[x+1, y+1])\n",
    "        newImage[int(x/2),int(y/2)] = max(pixels)\n",
    "\n",
    "# Plot the image. Note the size of the axes -- now 256 pixels instead of 512\n",
    "plt.gray()\n",
    "plt.grid(False)\n",
    "plt.imshow(newImage)\n",
    "#plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "i = misc.ascent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.grid(False)\n",
    "plt.gray()\n",
    "plt.axis('off')\n",
    "plt.imshow(i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_transformed = np.copy(i)\n",
    "size_x = i_transformed.shape[0]\n",
    "size_y = i_transformed.shape[1]\n",
    "# This filter detects edges nicely\n",
    "# It creates a convolution that only passes through sharp edges and straight\n",
    "# lines.\n",
    "\n",
    "#Experiment with different values for fun effects.\n",
    "#filter = [ [0, 1, 0], [1, -4, 1], [0, 1, 0]]\n",
    "\n",
    "# A couple more filters to try for fun!\n",
    "filter = [ [-1, -2, -1], [0, 0, 0], [1, 2, 1]]\n",
    "#filter = [ [-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]\n",
    "\n",
    "# If all the digits in the filter don't add up to 0 or 1, you \n",
    "# should probably do a weight to get it to do so\n",
    "# so, for example, if your weights are 1,1,1 1,2,1 1,1,1\n",
    "# They add up to 10, so you would set a weight of .1 if you want to normalize them\n",
    "weight  = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in range(1,size_x-1):\n",
    "    for y in range(1,size_y-1):\n",
    "        convolution = 0.0\n",
    "        convolution = convolution + (i[x - 1, y-1] * filter[0][0])\n",
    "        convolution = convolution + (i[x, y-1] * filter[0][1])\n",
    "        convolution = convolution + (i[x + 1, y-1] * filter[0][2])\n",
    "        convolution = convolution + (i[x-1, y] * filter[1][0])\n",
    "        convolution = convolution + (i[x, y] * filter[1][1])\n",
    "        convolution = convolution + (i[x+1, y] * filter[1][2])\n",
    "        convolution = convolution + (i[x-1, y+1] * filter[2][0])\n",
    "        convolution = convolution + (i[x, y+1] * filter[2][1])\n",
    "        convolution = convolution + (i[x+1, y+1] * filter[2][2])\n",
    "        convolution = convolution * weight\n",
    "        if(convolution<0):\n",
    "            convolution=0\n",
    "        if(convolution>255):\n",
    "            convolution=255\n",
    "        i_transformed[x, y] = convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the image. Note the size of the axes -- they are 512 by 512\n",
    "plt.gray()\n",
    "plt.grid(False)\n",
    "plt.imshow(i_transformed)\n",
    "#plt.axis('off')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_x = int(size_x/2)\n",
    "new_y = int(size_y/2)\n",
    "newImage = np.zeros((new_x, new_y))\n",
    "for x in range(0, size_x, 2):\n",
    "    for y in range(0, size_y, 2):\n",
    "        pixels = []\n",
    "        pixels.append(i_transformed[x, y])\n",
    "        pixels.append(i_transformed[x+1, y])\n",
    "        pixels.append(i_transformed[x, y+1])\n",
    "        pixels.append(i_transformed[x+1, y+1])\n",
    "        newImage[int(x/2),int(y/2)] = max(pixels)\n",
    "\n",
    "# Plot the image. Note the size of the axes -- now 256 pixels instead of 512\n",
    "plt.gray()\n",
    "plt.grid(False)\n",
    "plt.imshow(newImage)\n",
    "#plt.axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lodev.org/cgtutor/filtering.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=smHa2442Ah4&list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF&index=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "In the videos you looked at how you would improve Fashion MNIST using Convolutions. For your exercise see if you can improve MNIST to 99.8% accuracy or more using only a single convolutional layer and a single MaxPooling 2D. You should stop training once the accuracy goes above this amount. It should happen in less than 20 epochs, so it's ok to hard code the number of epochs for training, but your training must end once it hits the above metric. If it doesn't, then you'll need to redesign your layers.\n",
    "\n",
    "I've started the code for you -- you need to finish it!\n",
    "\n",
    "When 99.8% accuracy has been hit, you should print out the string \"Reached 99.8% accuracy so cancelling training!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# YOUR CODE STARTS HERE\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs = {}):\n",
    "        if(logs.get('acc') > 0.998):\n",
    "            print('\\nReached 99.8% accuracy')\n",
    "            self.model.stop_training = True\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "callbacks = myCallback()\n",
    "# YOUR CODE ENDS HERE\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# YOUR CODE STARTS HERE\n",
    "training_images = training_images.reshape(60000, 28, 28, 1)\n",
    "training_images = training_images / 255.0\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images = test_images / 255.0\n",
    "# YOUR CODE ENDS HERE\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    # YOUR CODE STARTS HERE\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape = (28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "    # YOUR CODE ENDS HERE\n",
    "])\n",
    "\n",
    "# YOUR CODE STARTS HERE\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()\n",
    "model.fit(training_images, training_labels, epochs = 10, callbacks = [callbacks])\n",
    "test_loss = model.evaluate(test_images, test_labels)\n",
    "# YOUR CODE ENDS HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horse or Human"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "local_zip = 'horse-or-human.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('horse-or-human')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_horse_dir = os.path.join('horse-or-human/horse-or-human/horses')\n",
    "train_human_dir = os.path.join('horse-or-human/horse-or-human/humans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_horse_names = os.listdir(train_horse_dir)\n",
    "print(train_horse_names[100:110])\n",
    "train_human_names = os.listdir(train_human_dir)\n",
    "print(train_human_names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(os.listdir(train_horse_dir)))\n",
    "print(len(os.listdir(train_human_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplot.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "pic_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols * 4, nrows * 4)\n",
    "\n",
    "pic_index += 8\n",
    "next_horse_pix = [os.path.join(train_horse_dir, fname) \n",
    "                for fname in train_horse_names[pic_index-8:pic_index]]\n",
    "next_human_pix = [os.path.join(train_human_dir, fname) \n",
    "                for fname in train_human_names[pic_index-8:pic_index]]\n",
    "\n",
    "for i, img_path in enumerate(next_horse_pix+next_human_pix):\n",
    "  # Set up subplot; subplot indices start at 1\n",
    "    sp = plt.subplot(nrows, ncols, i + 1)\n",
    "    sp.axis('Off') # Don't show axes (or gridlines)\n",
    "\n",
    "    img = mpimg.imread(img_path)\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fourth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fifth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'horse-or-human/horse-or-human',  # This is the source directory for training images\n",
    "        target_size=(300, 300),  # All images will be resized to 150x150\n",
    "        batch_size=128,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=8,  \n",
    "      epochs=15,\n",
    "      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from google.colab import files\n",
    "from keras.preprocessing import image\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    " \n",
    "  # predicting images\n",
    "    path = '/content/' + fn\n",
    "    img = image.load_img(path, target_size=(300, 300))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    images = np.vstack([x])\n",
    "    classes = model.predict(images, batch_size=10)\n",
    "    print(classes[0])\n",
    "    if classes[0]>0.5:\n",
    "        print(fn + \" is a human\")\n",
    "    else:\n",
    "        print(fn + \" is a horse\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Intermediate Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "# Let's define a new Model that will take an image as input, and will output\n",
    "# intermediate representations for all layers in the previous model after\n",
    "# the first.\n",
    "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
    "#visualization_model = Model(img_input, successive_outputs)\n",
    "visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n",
    "# Let's prepare a random input image from the training set.\n",
    "horse_img_files = [os.path.join(train_horse_dir, f) for f in train_horse_names]\n",
    "human_img_files = [os.path.join(train_human_dir, f) for f in train_human_names]\n",
    "img_path = random.choice(horse_img_files + human_img_files)\n",
    "\n",
    "img = load_img(img_path, target_size=(300, 300))  # this is a PIL image\n",
    "x = img_to_array(img)  # Numpy array with shape (150, 150, 3)\n",
    "x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n",
    "\n",
    "# Rescale by 1/255\n",
    "x /= 255\n",
    "\n",
    "# Let's run our image through our network, thus obtaining all\n",
    "# intermediate representations for this image.\n",
    "successive_feature_maps = visualization_model.predict(x)\n",
    "\n",
    "# These are the names of the layers, so can have them as part of our plot\n",
    "layer_names = [layer.name for layer in model.layers]\n",
    "\n",
    "# Now let's display our representations\n",
    "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
    "    if len(feature_map.shape) == 4:\n",
    "    # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
    "        n_features = feature_map.shape[-1]  # number of features in feature map\n",
    "    # The feature map has shape (1, size, size, n_features)\n",
    "        size = feature_map.shape[1]\n",
    "    # We will tile our images in this matrix\n",
    "        display_grid = np.zeros((size, size * n_features))\n",
    "    for i in range(n_features):\n",
    "      # Postprocess the feature to make it visually palatable\n",
    "        x = feature_map[0, :, :, i]\n",
    "        x -= x.mean()\n",
    "        x /= x.std()\n",
    "        x *= 64\n",
    "        x += 128\n",
    "        x = np.clip(x, 0, 255).astype('uint8')\n",
    "      # We'll tile each filter into this big horizontal grid\n",
    "        display_grid[:, i * size : (i + 1) * size] = x\n",
    "    # Display the grid\n",
    "    scale = 20. / n_features\n",
    "    plt.figure(figsize=(scale * n_features, scale))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, signal\n",
    "os.kill(os.getpid(), signal.SIGKILL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Below is code with a link to a happy or sad dataset which contains 80 images, 40 happy and 40 sad. Create a convolutional neural network that trains to 100% accuracy on these images, which cancels training upon hitting training accuracy of >.999\n",
    "Hint -- it will work best with 3 convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "\n",
    "DESIRED_ACCURACY = 0.999\n",
    "\n",
    "!wget --no-check-certificate \\\n",
    "    \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/happy-or-sad.zip\" \\\n",
    "    -O \"/tmp/happy-or-sad.zip\"\n",
    "\n",
    "zip_ref = zipfile.ZipFile(\"/tmp/happy-or-sad.zip\", 'r')\n",
    "zip_ref.extractall(\"/tmp/h-or-s\")\n",
    "zip_ref.close()\n",
    "\n",
    "    \n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs = {}):\n",
    "        if(logs.get('acc') > DESIRED_ACCURACY):\n",
    "            print('\\nReached 99.9% accuracy')\n",
    "            self.model.stop_training = True\n",
    "  # Your Code\n",
    "\n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Code Block should Define and Compile the Model\n",
    "model = tf.keras.models.Sequential([\n",
    "# Your Code Here\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation = 'relu', input_shape = (300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = RMSprop(lr = 0.001),\n",
    "             metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block should create an instance of an ImageDataGenerator called train_datagen \n",
    "# And a train_generator by calling train_datagen.flow_from_directory\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1/255)# Your Code Here\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "'/tmp/h-or-s',\n",
    "target_size = (300, 300),\n",
    "batch_size = 128,\n",
    "class_mode = 'binary')\n",
    "        # Your Code Here)\n",
    "\n",
    "# Expected output: 'Found 80 images belonging to 2 classes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code block should call model.fit_generator and train for\n",
    "# a number of epochs. \n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch = 8,\n",
    "      epochs = 15,\n",
    "      verbose = 1,\n",
    "      callbacks = [callbacks]\n",
    ")\n",
    "    \n",
    "# Expected output: \"Reached 99.9% accuracy so cancelling training!\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
